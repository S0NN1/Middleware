\documentclass[table, 12pt]{article}
\usepackage{graphicx}
\usepackage{listings}



\begin{document}

\begin{titlepage}
		\centering
		{\scshape\large AY 2020/2021 \par}
		\vfill
		\includegraphics[width=100pt]{assets/logo-polimi-new}\par\vspace{1cm}
		{\scshape\LARGE Politecnico di Milano \par}
		\vspace{1.5cm}
		{\huge\bfseries Middleware Technologies\\Analysis of COVID-19 Data\par}
		\vspace{2cm}
		{\Large {Federico Armellini\quad Luca Pirovano\quad Nicol√≤ Sonnino}\par}
		\vfill
		{\large Professor\par
			Alessandro \textsc{Margara}}
		\vfill
		{\large \textbf{Version 1.1}\\ \today \par}
	\end{titlepage}

	\thispagestyle{plain}
	\pagenumbering{gobble}
	\mbox{}
	\newpage
	\pagenumbering{roman}
	\tableofcontents
	\newpage
	\pagenumbering{arabic}
	
	
\section{Introduction and assignment}
\subsection{Description of the project}
In this project, you have to implement a program that analyzes open datasets to study the evolution of the
COVID-19 situation worldwide. The program starts from the dataset of new reported cases for each country
daily and computes the following queries:

\begin{enumerate}


\item Seven days moving average of new reported cases, for each county and for each day
\item Percentage increase (with respect to the day before) of the seven days moving average, for each country
and for each day
\item Top 10 countries with the highest percentage increase of the seven days moving average, for each day
\end{enumerate}
You can either use real open datasets 1 or synthetic data generated with the simulator developed for Project 4.
A performance analysis of the proposed solution is appreciated (but not mandatory). In particular, we are
interested in studies that evaluate (1) how the execution time changes when increasing the size of the dataset
and/or number of countries; (2) how the execution time decreases when adding more processing cores/hosts.

\subsection{Assumptions and guidelines}
 \begin{itemize}
 

 
 \item
When using a real dataset, for countries that provide weekly reports, you can assume that the weekly increment is evenly spread across the day of the week.

 \end{itemize}



\section{Solution Overview}
\subsection{Architecture chosen}
Apache Spark



\subsection{Assumptions and Definitions}
\begin{itemize}


\setlength\itemsep{-0.5em}
	\item The dataset is in CSV format. Each line contains day, rank, number of infected people, number of sane people, number of newly infected people (then the day before), the number of new sane people (then the day before).
\end{itemize}

\subsection{General solution}

The project is based on SparkSQL library, which permits doing SQL query and distribute them among the machines in the Apache Spark cluster.

We used the data provided from ECDC (European Centre For Disease Control and Prevention) which has a general report of Covid-19 in 2020.

\subsection{Queries}
\subsubsection{Query 1}


The first query goal is to calculate a moving average of a window of 7 days.

To do this, we adopted the following approach:
\lstset{%
caption=,
basicstyle=\ttfamily\footnotesize\bfseries,
frame=tb
}
\begin{lstlisting}[language=Java, caption=Query 1]
	final WindowSpec ws1 = Window
	.partitionBy("countriesAndTerritories")
	.orderBy("date", "geoId")
	.rowsBetween(-6,0);

	final Column col1 = functions.avg("cases").over(ws1);

	final Dataset<Row> df1 = df
	.withColumn("date", functions
		.to_timestamp(df.col("dateRep"), "dd/MM/yyyy"))
	.withColumn("movingAverage", functions.round(col1, 2));
\end{lstlisting}

The Window declaration defines a custom window which is:
\begin{itemize}
	\item partitioned by countries name;
	\item ordered by their geoId and date of observation
	\item 7 days large, which means that it considers a week from the day considered.
\end{itemize}

\subsubsection{Query 2}
The second query goal is to calculate the percentage increase of the moving average calculated at point 1 with respect to the day before.

\lstset{%
caption=,
basicstyle=\ttfamily\footnotesize\bfseries,
frame=tb
}
\begin{lstlisting}[language=Java, caption=Query 2]
	final WindowSpec ws2 = Window
	.partitionBy("countriesAndTerritories")
	.orderBy("date", "geoId");

	final Dataset<Row> df2 = df1
	.withColumn("prevValue", functions
		.round(functions.lag("movingAverage", 1).over(ws2), 2));

	final Column col3 = df2
	.col("movingAverage").minus(df2.col("prevValue"));

	final Column col2 = col3
	.divide(df2.col("prevValue")).multiply(100).cast("float");

	Dataset<Row> df3 = df2
	.withColumn("perc_increase", functions
		.when(functions.isnull(col3),0)
		.otherwise(functions.round(col2, 2))).drop("prevValue");

	df3 = df3.filter(df3.col("perc_increase").isNotNull());
\end{lstlisting}

Again we have a window which is the same of the one declared for query 1.

Then, we create a new column \textit{prevValue} which represent the moving average value of the day before.

This value is then used to create a column \textit{perc\_increase} which is calculated in that way.

$perc\_increase = \displaystyle{\frac{maCurrent - maDayBefore}{maDayBefore} * 100}$

\subsubsection{Query 3}
\lstset{%
caption=,
basicstyle=\ttfamily\footnotesize\bfseries,
frame=tb
}
\begin{lstlisting}[language=Java, caption=Query 3]
	final WindowSpec ws3 = Window
	.partitionBy("date")
	.orderBy(functions.desc("perc_increase"));

	final Dataset<Row> df4 = df3
	.withColumn("rankingPercIncrease", rank().over(ws3));

	final Dataset<Row> df5 = df4
	.where("rankingPercIncrease<=" + maxRankCountries)
	.orderBy("date", "rankingPercIncrease");
\end{lstlisting}
Again we have a window which is the same of the one declared for query 1.

Then, we calculate the rank of nations relying on their percentage increase.



\end{document}